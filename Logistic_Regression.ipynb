{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Code: DA-AG-011\n",
        "\n",
        "# Logistic Regression | Assignment"
      ],
      "metadata": {
        "id": "sjP0vWE8ZLjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1:  What is Logistic Regression, and how does it differ from Linear Regression?"
      ],
      "metadata": {
        "id": "qFUK6n4GZgJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression** is a **statistical model used for binary classification** problems — that is, problems where the outcome variable has two possible values (e.g., yes/no, 0/1, true/false). It predicts the **probability** that a given input belongs to a particular category.\n",
        "\n",
        "\n",
        "### **Key Differences Between Logistic Regression and Linear Regression:**\n",
        "\n",
        "| Feature           | **Linear Regression**                                  | **Logistic Regression**                                       |\n",
        "| ----------------- | ------------------------------------------------------ | ------------------------------------------------------------- |\n",
        "| **Purpose**       | Predicts **continuous** numerical values               | Predicts **probability** of a binary outcome (classification) |\n",
        "| **Output**        | Real numbers (can be any value from -∞ to +∞)          | Values between **0 and 1** (probabilities)                    |\n",
        "| **Function Used** | Linear function: `y = β₀ + β₁x + ... + βₙxₙ`           | Logistic (sigmoid) function: `P = 1 / (1 + e^-(β₀ + β₁x))`    |\n",
        "| **Linearity**     | Assumes a linear relationship between input and output | Models a **log-odds linear** relationship                     |\n",
        "| **Loss Function** | Mean Squared Error (MSE)                               | Binary Cross-Entropy (Log Loss)                               |\n",
        "| **Used For**      | Regression tasks (e.g., predicting price, temperature) | Classification tasks (e.g., spam detection, churn prediction) |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YFvzbstnZn4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2:  Explain the role of the Sigmoid function in Logistic Regression."
      ],
      "metadata": {
        "id": "PQzC7S28aId5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Sigmoid function** plays a central role in **Logistic Regression** by converting the output of a linear equation into a **probability value between 0 and 1**, which is ideal for binary classification.\n",
        "\n",
        "###  **Definition of the Sigmoid Function:**\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n$ is the linear combination of input features.\n",
        "* $\\sigma(z)$ is the predicted probability that the output is class 1 (positive class).\n",
        "\n",
        "### **Role of the Sigmoid in Logistic Regression:**\n",
        "\n",
        "1. **Transforms Linear Output to Probability:**\n",
        "\n",
        "   * The raw linear combination $z$ can range from $-\\infty$ to $+\\infty$.\n",
        "   * The sigmoid squashes this into a **probability range of (0, 1)**.\n",
        "\n",
        "2. **Decision Boundary:**\n",
        "\n",
        "   * If $\\sigma(z) \\geq 0.5$, classify as **class 1**\n",
        "   * If $\\sigma(z) < 0.5$, classify as **class 0**\n",
        "   * This threshold can be adjusted based on the problem.\n",
        "\n",
        "3. **Enables Probabilistic Interpretation:**\n",
        "\n",
        "   * Output is not just a class, but a **confidence score** or probability of belonging to a class.\n",
        "\n",
        "### **Visualization Insight:**\n",
        "\n",
        "The sigmoid function has an \"S\"-shaped curve:\n",
        "\n",
        "* Steep near 0 and 1, flat in the middle.\n",
        "* Output:\n",
        "\n",
        "  * Close to 0 when $z \\ll 0$\n",
        "  * Close to 1 when $z \\gg 0$\n",
        "  * Exactly 0.5 when $z = 0$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q0fBNryLaL9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: What is Regularization in Logistic Regression and why is it needed?"
      ],
      "metadata": {
        "id": "RcBWYEwpabBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regularization** is a technique used to **prevent overfitting** in machine learning models, including **Logistic Regression**. It works by **adding a penalty term to the loss function**, discouraging the model from fitting too closely to the training data (i.e., keeping the model simpler and more generalizable).\n",
        "\n",
        "### Why is Regularization Needed?\n",
        "\n",
        "Without regularization:\n",
        "\n",
        "* The model may **learn noise** or irrelevant patterns in the training data.\n",
        "* This leads to **high accuracy on training data** but **poor performance on unseen data** (overfitting).\n",
        "\n",
        "With regularization:\n",
        "\n",
        "* The model is **penalized for using large weights**, which often indicate over-reliance on specific features.\n",
        "* It encourages **simpler models** that generalize better.\n",
        "\n",
        "###  Types of Regularization in Logistic Regression\n",
        "\n",
        "| Type            | Penalty Term             | Effect                                                                       |   |                                                                     |\n",
        "| --------------- | ------------------------ | ---------------------------------------------------------------------------- | - | ------------------------------------------------------------------- |\n",
        "| **L1 (Lasso)**  | ( \\lambda \\sum           | \\beta\\_j                                                                     | ) | Encourages sparsity – **some weights become 0** (feature selection) |\n",
        "| **L2 (Ridge)**  | $\\lambda \\sum \\beta_j^2$ | Encourages small weights – **shrinks all weights**, but none go exactly to 0 |   |                                                                     |\n",
        "| **Elastic Net** | Combines L1 and L2       | Mix of sparsity and shrinkage                                                |   |                                                                     |\n",
        "\n",
        "Where:\n",
        "\n",
        "* $\\beta_j$ = model coefficients\n",
        "* $\\lambda$ = regularization strength (higher = more penalty)\n",
        "\n",
        "###  Modified Loss Function (e.g., for L2 Regularization):\n",
        "\n",
        "$$\n",
        "\\text{Loss} = \\text{Log Loss} + \\lambda \\sum_{j=1}^n \\beta_j^2\n",
        "$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nXw5pX8tafqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4:  What are some common evaluation metrics for classification models, and why are they important?"
      ],
      "metadata": {
        "id": "EB3j7y_nazlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metrics help us **measure the performance** of a classification model. They are **crucial** because they show **how well your model is working**, and different metrics are useful depending on the **problem context** (e.g., fraud detection vs spam filtering).\n",
        "\n",
        "### **Common Evaluation Metrics for Classification:**\n",
        "\n",
        "| **Metric**               | **Description**                                                                  | **When to Use**                                            |\n",
        "| ------------------------ | -------------------------------------------------------------------------------- | ---------------------------------------------------------- |\n",
        "| **Accuracy**             | $\\frac{\\text{Correct Predictions}}{\\text{Total Predictions}}$                    | When classes are balanced                                  |\n",
        "| **Precision**            | $\\frac{TP}{TP + FP}$ – How many predicted positives are actual positives         | Important when **false positives** are costly              |\n",
        "| **Recall (Sensitivity)** | $\\frac{TP}{TP + FN}$ – How many actual positives are correctly predicted         | Important when **false negatives** are costly              |\n",
        "| **F1 Score**             | Harmonic mean of Precision and Recall                                            | Useful when **classes are imbalanced**                     |\n",
        "| **ROC-AUC Score**        | Area under the ROC curve (TPR vs FPR)                                            | Measures **model discrimination ability**                  |\n",
        "| **Confusion Matrix**     | Table showing TP, TN, FP, FN counts                                              | Visual breakdown of model performance                      |\n",
        "| **Log Loss**             | Measures the model’s uncertainty in predictions (penalizes confident wrong ones) | Good for **probabilistic models** like logistic regression |\n",
        "\n",
        "### **Confusion Matrix Terms:**\n",
        "\n",
        "|                     | Predicted Positive  | Predicted Negative  |\n",
        "| ------------------- | ------------------- | ------------------- |\n",
        "| **Actual Positive** | True Positive (TP)  | False Negative (FN) |\n",
        "| **Actual Negative** | False Positive (FP) | True Negative (TN)  |\n",
        "\n",
        "### Why These Metrics Are Important:\n",
        "\n",
        "1. **Accuracy alone can be misleading** in imbalanced datasets (e.g., cancer detection where 99% are healthy).\n",
        "2. **Precision vs Recall trade-off** helps you choose what error type is more acceptable.\n",
        "3. **F1 Score** balances both precision and recall for uneven classes.\n",
        "4. **ROC-AUC** gives an overall performance measure, independent of threshold.\n",
        "\n",
        "### Example:\n",
        "\n",
        "In spam detection:\n",
        "\n",
        "* High **precision** = fewer legitimate emails marked as spam (low FP).\n",
        "* High **recall** = fewer spam emails go undetected (low FN).\n",
        "* **F1 score** helps balance both if needed.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FIyj4fwqbHWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "UL8p1CnCbgNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression # Import LogisticRegression\n",
        "\n",
        "# Load breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Split into train/test sets (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Q4p8yKhIrA",
        "outputId": "53daf2df-2e94-4f65-993f-de6b1f9de0b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6:  Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "fft4jHN5b9w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model using L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients (L2 Regularization):\\n\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EviDxgXCjp9k",
        "outputId": "6149ac96-8360-4d19-ce4b-be9bfa56995c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients (L2 Regularization):\n",
            "\n",
            "mean radius: 2.1325\n",
            "mean texture: 0.1528\n",
            "mean perimeter: -0.1451\n",
            "mean area: -0.0008\n",
            "mean smoothness: -0.1426\n",
            "mean compactness: -0.4156\n",
            "mean concavity: -0.6519\n",
            "mean concave points: -0.3445\n",
            "mean symmetry: -0.2076\n",
            "mean fractal dimension: -0.0298\n",
            "radius error: -0.0500\n",
            "texture error: 1.4430\n",
            "perimeter error: -0.3039\n",
            "area error: -0.0726\n",
            "smoothness error: -0.0162\n",
            "compactness error: -0.0019\n",
            "concavity error: -0.0449\n",
            "concave points error: -0.0377\n",
            "symmetry error: -0.0418\n",
            "fractal dimension error: 0.0056\n",
            "worst radius: 1.2321\n",
            "worst texture: -0.4046\n",
            "worst perimeter: -0.0362\n",
            "worst area: -0.0271\n",
            "worst smoothness: -0.2626\n",
            "worst compactness: -1.2090\n",
            "worst concavity: -1.6180\n",
            "worst concave points: -0.6153\n",
            "worst symmetry: -0.7428\n",
            "worst fractal dimension: -0.1170\n",
            "\n",
            "Model Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "xSgKwjb_cbSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model for multiclass classification using OvR\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uDUgV2aAR5-",
        "outputId": "8ceda06e-c5f0-4b34-ad06-0e95cc5a0634"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "xLkveSVpc9WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # Using Breast Cancer dataset\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset from sklearn\n",
        "print(\"Loading Breast Cancer dataset from sklearn...\")\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Classes: {cancer.target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split into train/test sets (using the same split as Q6 for consistency)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features (important for regularization)\n",
        "print(\"\\nStandardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "\n",
        "print(\"\\nPerforming GridSearchCV...\")\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the scaled training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"GridSearchCV complete.\\n\")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print the best cross-validation score (accuracy)\n",
        "print(\"\\nBest cross-validation accuracy:\")\n",
        "print(f\"{grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\nTest set accuracy with best parameters:\")\n",
        "print(f\"{test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Optional: Print classification report for the best model on the test set\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nClassification Report on Test Set with Best Model:\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=cancer.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkYV6W0dmgvI",
        "outputId": "8792b212-f2fd-4b4c-9e27-1a009584d847"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset from sklearn...\n",
            "Dataset shape: (569, 30)\n",
            "Classes: ['malignant' 'benign']\n",
            "Class distribution: [212 357]\n",
            "\n",
            "Standardizing features...\n",
            "Training set shape: (455, 30)\n",
            "Test set shape: (114, 30)\n",
            "\n",
            "Performing GridSearchCV...\n",
            "GridSearchCV complete.\n",
            "\n",
            "Best parameters found by GridSearchCV:\n",
            "{'C': 1, 'penalty': 'l2'}\n",
            "\n",
            "Best cross-validation accuracy:\n",
            "0.9802\n",
            "\n",
            "Test set accuracy with best parameters:\n",
            "0.9825 (98.25%)\n",
            "\n",
            "Classification Report on Test Set with Best Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.98      0.98        42\n",
            "      benign       0.99      0.99      0.99        72\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "0AlwJgZ3dQD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # Using Breast Cancer dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset from sklearn\n",
        "print(\"Loading Breast Cancer dataset from sklearn...\")\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Classes: {cancer.target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n",
        "# --- Train model WITHOUT scaling ---\n",
        "print(\"\\nTraining Logistic Regression model WITHOUT scaling...\")\n",
        "model_no_scale = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear') # Use a suitable solver\n",
        "model_no_scale.fit(X_train, y_train)\n",
        "y_pred_no_scale = model_no_scale.predict(X_test)\n",
        "accuracy_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "\n",
        "print(f\"Accuracy WITHOUT scaling: {accuracy_no_scale:.4f} ({accuracy_no_scale*100:.2f}%)\")\n",
        "\n",
        "# --- Train model WITH scaling ---\n",
        "print(\"\\nStandardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Training Logistic Regression model WITH scaling...\")\n",
        "model_scaled = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy WITH scaling:    {accuracy_scaled:.4f} ({accuracy_scaled*100:.2f}%)\")\n",
        "\n",
        "# --- Comparison ---\n",
        "print(\"\\nComparison of Accuracy:\")\n",
        "print(f\"  Without Scaling: {accuracy_no_scale:.4f}\")\n",
        "print(f\"  With Scaling:    {accuracy_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzbjW4i2Cz3l",
        "outputId": "8faa8932-2e5e-4ac7-fda0-d7a89c0eab35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset from sklearn...\n",
            "Dataset shape: (569, 30)\n",
            "Classes: ['malignant' 'benign']\n",
            "Class distribution: [212 357]\n",
            "\n",
            "Training set shape: (455, 30)\n",
            "Test set shape: (114, 30)\n",
            "\n",
            "Training Logistic Regression model WITHOUT scaling...\n",
            "Accuracy WITHOUT scaling: 0.9561 (95.61%)\n",
            "\n",
            "Standardizing features...\n",
            "Training Logistic Regression model WITH scaling...\n",
            "Accuracy WITH scaling:    0.9825 (98.25%)\n",
            "\n",
            "Comparison of Accuracy:\n",
            "  Without Scaling: 0.9561\n",
            "  With Scaling:    0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case."
      ],
      "metadata": {
        "id": "-aviy4OwdhNy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acc777a3"
      },
      "source": [
        "## Approach to Building a Logistic Regression Model for Imbalanced Data (E-commerce Marketing Campaign)\n",
        "\n",
        "Given an imbalanced dataset where only 5% of customers respond to a marketing campaign, building a robust Logistic Regression model requires careful consideration of data handling, class imbalance, and evaluation. Here’s a step-by-step approach:\n",
        "\n",
        "**1. Data Handling and Preprocessing:**\n",
        "\n",
        "*   **Data Loading and Exploration:** Load the customer data (features like purchase history, demographics, browsing behavior, past campaign interactions, etc.) into a Pandas DataFrame. Perform initial exploratory data analysis (EDA) to understand feature distributions, identify missing values, and analyze the class distribution (confirm the 5% response rate).\n",
        "*   **Feature Engineering:** Create new features that might be predictive of response. This could include:\n",
        "    *   Recency, Frequency, Monetary (RFM) values.\n",
        "    *   Number of visits in the last X days.\n",
        "    *   Time spent on site.\n",
        "    *   Category preferences.\n",
        "    *   Interaction counts with previous campaigns.\n",
        "*   **Handling Missing Values:** Impute or remove missing values based on their extent and the nature of the feature.\n",
        "*   **Encoding Categorical Features:** Convert categorical variables (e.g., gender, location) into numerical formats using techniques like One-Hot Encoding.\n",
        "\n",
        "**2. Feature Scaling:**\n",
        "\n",
        "*   **Standardization or Normalization:** Since Logistic Regression uses gradient descent and can be sensitive to feature scales, it's crucial to scale the numerical features. `StandardScaler` (z-score normalization) or `MinMaxScaler` are common choices. Apply the scaling *after* splitting the data to prevent data leakage from the test set into the training process.\n",
        "\n",
        "**3. Handling Class Imbalance:**\n",
        "\n",
        "This is a critical step for imbalanced datasets. Directly training on the imbalanced data will likely result in a model that predicts the majority class (non-responders) most of the time, leading to high accuracy but poor performance on the minority class (responders), which is the class of interest. Techniques include:\n",
        "\n",
        "*   **Resampling Techniques:**\n",
        "    *   **Oversampling the Minority Class:** Duplicate instances of the minority class (responders) to increase their representation. SMOTE (Synthetic Minority Oversampling Technique) is a popular method that creates synthetic samples of the minority class.\n",
        "    *   **Undersampling the Majority Class:** Randomly remove instances of the majority class (non-responders). This can lead to loss of valuable information.\n",
        "    *   **Combination Approaches:** Techniques like SMOTEENN or SMOTETomek combine oversampling and undersampling.\n",
        "*   **Using Class Weights:** Logistic Regression models in libraries like scikit-learn allow assigning higher weights to the minority class during training. This tells the model to penalize misclassifications of the minority class more heavily. This is often simpler and performs well compared to resampling.\n",
        "\n",
        "**Choose the appropriate technique based on experimentation and cross-validation.** Using class weights is often a good starting point.\n",
        "\n",
        "**4. Model Training:**\n",
        "\n",
        "*   **Splitting Data:** Split the preprocessed and potentially balanced data into training, validation (optional but recommended), and testing sets. A common split is 70/15/15 or 80/20 for train/test, with a portion of the training data used for validation during hyperparameter tuning. Ensure the split is stratified to maintain the class distribution in each set.\n",
        "*   **Logistic Regression Model:** Initialize a `LogisticRegression` model from scikit-learn.\n",
        "\n",
        "**5. Hyperparameter Tuning:**\n",
        "\n",
        "*   **Parameters to Tune:** Key hyperparameters for Logistic Regression include:\n",
        "    *   `C`: The inverse of regularization strength. Smaller values mean stronger regularization (L2 by default). This helps prevent overfitting.\n",
        "    *   `penalty`: 'l1' or 'l2' regularization. L1 can lead to sparser coefficients (feature selection), while L2 shrinks coefficients.\n",
        "    *   `solver`: The algorithm to use for optimization (e.g., 'liblinear', 'lbfgs', 'saga').\n",
        "    *   `class_weight`: Use `'balanced'` to automatically adjust weights inversely proportional to class frequencies, or provide a dictionary of weights.\n",
        "*   **Tuning Method:** Use techniques like `GridSearchCV` or `RandomizedSearchCV` with cross-validation on the training (or training + validation) data to find the optimal combination of hyperparameters that maximizes a suitable evaluation metric.\n",
        "\n",
        "**6. Model Evaluation:**\n",
        "\n",
        "*   **Choosing Appropriate Metrics:** Since the dataset is imbalanced, accuracy is **not** a good primary evaluation metric. A model that predicts 'non-responder' for all customers would have 95% accuracy. Focus on metrics that are sensitive to the performance on the minority class:\n",
        "    *   **Precision:** Out of all customers predicted as responders, how many actually responded? High precision is important if false positives (contacting non-responders) are costly.\n",
        "    *   **Recall (Sensitivity):** Out of all actual responders, how many did the model correctly identify? High recall is important if false negatives (missing potential responders) are costly. In a marketing campaign, recall is often very important to capture as many potential responders as possible, even if it means contacting some non-responders.\n",
        "    *   **F1-Score:** The harmonic mean of precision and recall. A good balance between the two. Useful when you need a balance.\n",
        "    *   **ROC-AUC:** Measures the model's ability to distinguish between the positive and negative classes across different probability thresholds. A higher AUC indicates better discriminative power. This is often a good overall metric for imbalanced data.\n",
        "    *   **Confusion Matrix:** Provides a detailed breakdown of true positives, true negatives, false positives, and false negatives.\n",
        "*   **Evaluation on Test Set:** Evaluate the best model found during hyperparameter tuning on the held-out test set using the chosen metrics. The test set provides an unbiased estimate of the model's performance on unseen data.\n",
        "\n",
        "**7. Threshold Adjustment:**\n",
        "\n",
        "*   **Optimizing for the Business Goal:** The default probability threshold for classification is 0.5. However, in an imbalanced scenario, you can adjust this threshold based on the business objective.\n",
        "    *   If you prioritize recall (finding more responders), you might lower the threshold.\n",
        "    *   If you prioritize precision (minimizing contact with non-responders), you might raise the threshold.\n",
        "    *   Analyze the Precision-Recall curve or ROC curve to determine the optimal threshold that balances the trade-off between precision and recall for the specific campaign goals (e.g., maximizing the number of responders contacted while keeping the cost of contacting non-responders manageable).\n",
        "\n",
        "**Summary:**\n",
        "\n",
        "Building a Logistic Regression model for an imbalanced marketing campaign dataset involves standard data processing, crucial handling of class imbalance (using techniques like class weights or resampling), hyperparameter tuning using appropriate metrics like F1-score or ROC-AUC, and careful evaluation on a held-out test set. Finally, adjusting the prediction threshold based on the business objective (balancing precision and recall) is key to deploying an effective model.\n",
        "\n",
        "---"
      ]
    }
  ]
}